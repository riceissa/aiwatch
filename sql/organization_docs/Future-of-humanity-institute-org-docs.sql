insert into organization_documents(url, title, publication_date, modified_date, author, publisher, affected_organizations, affected_people, document_scope, cause_area, notes) values
   (
        'https://forum.effectivealtruism.org/posts/uK27pds7J36asqJPt/future-of-humanity-institute-2005-2024-final-report', /* url */
        'Future of Humanity Institute 2005-2024: Final Report', /* title */
        '2024-04-17', /* publication_date */
        NULL, /* modified_date */
        'Pablo', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'Building effective altruism', /* cause_area */
        'Sandberg''s final report on the Future of Humanity Institute (FHI) reflects on its successes and challenges from 2005 to 2024, highlighting FHI''s impact on long-term research fields, interdisciplinary collaboration, and operational insights for future existential risk research.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/WTBqQbzqW894aZL6u/future-of-humanity-institute-is-hiring', /* url */
        'Future of Humanity Institute is hiring', /* title */
        '2015-12-08', /* publication_date */
        NULL, /* modified_date */
        'Andrew_SB', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Andrew_SB provides a brief on the Future of Humanity Institute’s 2015 hiring for research roles focused on AI safety, policy, strategy, and existential risk, highlighting the institute''s mission to tackle civilization-scale challenges.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/gLpAai6D3HertcXhQ/research-position-at-future-of-humanity-institute', /* url */
        'Research position at Future of Humanity Institute', /* title */
        '2015-04-15', /* publication_date */
        NULL, /* modified_date */
        'Daniel Dewey', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Dewey announces the Future of Humanity Institute’s call for a Postdoctoral Research Fellow to conduct AI safety research with Professor Nick Bostrom, emphasizing a long-term focus on machine intelligence risks.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/XyYxLzdxNzhCZFsci/throwing-the-institutional-baby-out-with-the-bathwater', /* url */
        'Throwing the institutional baby out with the bathwater: Physicist & YouTuber Sabine Hossenfelder''s superficial and sensationalist take on the demise of the Future of Humanity Institute', /* title */
        '2024-05-02', /* publication_date */
        NULL, /* modified_date */
        'Deborah W.A. Foulkes', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        'Sabine Hossenfelder', /* affected_people */
        'General discussion of organizational practices', /* document_scope */
        'AI safety', /* cause_area */
        'Foulkes critiques Sabine Hossenfelder''s video for undermining the Future of Humanity Institute''s significant work on AI risks and global regulation efforts amid recent challenges.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/4HcggJWghXogSS25b/job-opportunity-at-the-future-of-humanity-institute-and', /* url */
        'Job opportunity at the Future of Humanity Institute and Global Priorities Institute', /* title */
        '2018-04-18', /* publication_date */
        NULL, /* modified_date */
        'HaydenW', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        'Sabine Hossenfelder', /* affected_people */
        'Hiring-related notice', /* document_scope */
        'Building effective altruism', /* cause_area */
        'HaydenW highlights the Future of Humanity Institute''s need for a Senior Administrator to support its expansion in operations, covering finance, HR, and strategic management to drive long-term impact.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/5vGsFzWvh8Snet6sK/the-centre-for-the-governance-of-ai-has-relaunched', /* url */
        'The Centre for the Governance of AI has Relaunched', /* title */
        '2021-10-29', /* publication_date */
        NULL, /* modified_date */
        'GovAI', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'GovAI relaunches as a nonprofit in Oxford alongside the Future of Humanity Institute, expanding research, fellowships, and policy advising in AI governance.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/5vGsFzWvh8Snet6sK/the-centre-for-the-governance-of-ai-has-relaunched', /* url */
        'Differential technology development: preprint on the concept', /* title */
        '2022-09-12', /* publication_date */
        NULL, /* modified_date */
        'Hamish Hobbs| jbs| Allan Dafoe', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Hobbs, Sandbrink, Swett, Dafoe, and Sandberg at the Future of Humanity Institute present a preprint on differential technology development, advocating for prioritizing risk-reducing over risk-increasing technologies to mitigate existential threats from advanced AI and biotech.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/4BJSXH9ho4eYNT73P/how-dependent-is-the-effective-altruism-movement-on-dustin', /* url */
        'How Dependent is the Effective Altruism Movement on Dustin Moskovitz and Cari Tuna?', /* title */
        '2020-09-21', /* publication_date */
        NULL, /* modified_date */
        'Sapphire', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Benjamin Todd’s analysis shows that the Effective Altruism (EA) community infrastructure relies significantly on Good Ventures, with Dustin Moskovitz and Cari Tuna contributing an estimated 50-66% of total EA funding, supporting major organizations like the Future of Humanity Institute, which received £13.3 million in 2018 from the Open Philanthropy Project.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/bG9ZNvSmveNwryx8b/ama-owen-cotton-barratt-rsp-director', /* url */
        'AMA: Owen Cotton-Barratt, RSP Director', /* title */
        '2020-08-28', /* publication_date */
        NULL, /* modified_date */
        'Owen Cotton-Barratt', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'AMA', /* document_scope */
        'AI safety', /* cause_area */
        'Owen Cotton-Barratt discusses his role at the Future of Humanity Institute, focusing on the Research Scholars Programme and his research on decision-making under uncertainty, AI''s impact on effective altruism, and strategies to avoid catastrophic human behavior.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/7gxtXrMeqw78ZZeY9/ama-or-discuss-my-80k-podcast-episode-ben-garfinkel-fhi', /* url */
        'AMA or discuss my 80K podcast episode: Ben Garfinkel, FHI researcher', /* title */
        '2020-07-13', /* publication_date */
        NULL, /* modified_date */
        'Bgarfinkel', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'AMA', /* document_scope */
        'AI safety', /* cause_area */
        'Ben Garfinkel, a researcher at the Future of Humanity Institute, discusses AI safety, governance, and long-termist arguments in a podcast, offering insights into the importance of AI risk research and critiquing classic "fast takeoff" arguments.' /* notes */
    )
    ,(
        'forum.effectivealtruism.org/posts/EHiEZsAJfakvWwq5m/seeking-a-ceo-for-new-x-risk-funding-charity-in-the-uk', /* url */
        'Seeking a CEO for new x-risk funding charity in the UK', /* title */
        '2023-02-07', /* publication_date */
        NULL, /* modified_date */
        'Markus Anderljung', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Hiring-related notice', /* document_scope */
        'AI safety', /* cause_area */
        'Anderljung announces a CEO search for a new UK charity aimed at funding existential risk research and supporting the Future of Humanity Institute, emphasizing operational leadership and alignment with risk-reduction goals.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/9cx8TrLEooaw49cAr/i-m-cullen-o-keefe-a-policy-researcher-at-openai-ama', /* url */
        'I''m Cullen O''Keefe, a Policy Researcher at OpenAI, AMA', /* title */
        '2020-01-11', /* publication_date */
        NULL, /* modified_date */
        'Cullen', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'AMA', /* document_scope */
        'AI safety', /* cause_area */
        'Cullen O''Keefe, Policy Researcher at OpenAI and Research Affiliate at the Future of Humanity Institute, discusses his work on AGI governance, law''s intersection with AI, and effective altruism’s role in shaping equitable AI outcomes.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/9cx8TrLEooaw49cAr/i-m-cullen-o-keefe-a-policy-researcher-at-openai-ama', /* url */
        'The 25 researchers who have published the largest number of academic articles on existential risk', /* title */
        '2023-08-12', /* publication_date */
        NULL, /* modified_date */
        'FJehn', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'FJehn provides a ranked overview of the top 25 researchers in existential risk, highlighting key publications and affiliations, with a focus on active organizations like the Future of Humanity Institute and emerging AI-related risks.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/tdgvad64bmMxeXKws/have-you-ever-doubted-whether-you-re-good-enough-to-pursue', /* url */
        'Have You Ever Doubted Whether You''re Good Enough To Pursue Your Career?', /* title */
        '2022-04-11', /* publication_date */
        NULL, /* modified_date */
        'Lnette Bye', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Job experience', /* document_scope */
        'AI safety', /* cause_area */
        'The article captures insights from various leaders, including those at the Future of Humanity Institute, exploring their experiences with self-doubt and career challenges, revealing diverse personal strategies for managing productivity and impact within high-stakes fields like AI governance and effective altruism.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/33AnPajNYmNrdXQbj/rethink-priorities-2020-impact-and-2021-strategy', /* url */
        'Rethink Priorities 2020 Impact and 2021 Strategy', /* title */
        '2020-11-05', /* publication_date */
        NULL, /* modified_date */
        'Marcus_A_Davis', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'Building effective altruism', /* cause_area */
        'Rethink Priorities'' 2020 report highlights its expansion in research on animal welfare, longtermism, and EA movement building, aiming for increased impact through new hires, improved communication, and a $1.57M funding goal for 2021.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/CaY4AFcNrrtXybvDL/writing-about-my-job-research-fellow-fhi', /* url */
        'Writing about my job: Research Fellow, FHI', /* title */
        '2021-07-21', /* publication_date */
        NULL, /* modified_date */
        'Rgb', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Job experience', /* document_scope */
        'AI safety', /* cause_area */
        'RGB shares his journey to becoming a Research Fellow at the Future of Humanity Institute, detailing his academic background, the application process, and the challenges and rewards of working on AI consciousness and interdisciplinary research.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/Jj9HdQgTMctwRNQdu/ea-organization-updates-july-2020', /* url */
        'EA Organization Updates: July 2020', /* title */
        '2020-08-24', /* publication_date */
        NULL, /* modified_date */
        'Aaron Gertler ', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Aaron Gertler''s update highlights that the Future of Humanity Institute is hiring for its Research Scholars Programme, targeting early-career researchers for a selective, two-year fellowship focused on critical questions for humanity''s future.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/XweBntieePnzQyLtK/rowing-and-steering-the-effective-altruism-movement', /* url */
        'Rowing and Steering the Effective Altruism Movement', /* title */
        '2022-01-09', /* publication_date */
        NULL, /* modified_date */
        'Jtm ', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The article "Rowing and Steering the Effective Altruism Movement" by JTM discusses strategy and direction within the Effective Altruism movement, including the Future of Humanity Institute''s role in balancing immediate impact efforts with long-term existential risk reduction.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/59egqFgZBrfPqXWTr/ama-we-work-in-operations-at-ea-aligned-organizations-ask-us', /* url */
        'AMA: We Work in Operations at EA-aligned organizations. Ask Us Anything.', /* title */
        '2021-02-03', /* publication_date */
        NULL, /* modified_date */
        'Marisa', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'AMA', /* document_scope */
        'AI safety', /* cause_area */
        'This article shares insights from operations staff at EA-aligned organizations, including the Future of Humanity Institute, focusing on roles, skills, and career paths in operations within effective altruism.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/bfdc3MpsYEfDdvgtP/why-the-expected-numbers-of-farmed-animals-in-the-far-future', /* url */
        'Why the expected numbers of farmed animals in the far future might be huge', /* title */
        '2022-03-04', /* publication_date */
        NULL, /* modified_date */
        'Fai', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'Animal welfare', /* cause_area */
        'The article explores projections on farmed animal populations, examining Future of Humanity Institute''s'' implications for moral consideration and long-term welfare strategies.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/6h3a9bvJ2uYBfWxEM/ama-markus-anderljung-pm-at-govai-fhi-1', /* url */
        'AMA: Markus Anderljung (PM at GovAI, FHI)', /* title */
        '2020-09-21', /* publication_date */
        NULL, /* modified_date */
        'Markus Anderljung', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Markus Anderljung discusses GovAI''s ongoing projects at the Future of Humanity Institute, highlighting AI governance research priorities, hiring needs, and the broader impact of European AI policy.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/whDMv4NjsMcPrLq2b/cser-and-fhi-advice-to-un-high-level-panel-on-digital', /* url */
        'CSER and FHI advice to UN High-level Panel on Digital Cooperation', /* title */
        '2019-03-08', /* publication_date */
        NULL, /* modified_date */
        'Haydn Belfield', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute|CSER|UN', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The Future of Humanity Institute, alongside the Centre for the Study of Existential Risk, advises the UN on establishing AI governance mechanisms underpinned by inclusive, anticipatory, and responsive international cooperation frameworks for managing AI risks and ensuring global benefits.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/CNxteiKdRk9Hez3pv/ea-relevant-foresight-institute-workshops-in-2023-wbe-and-ai', /* url */
        'EA relevant Foresight Institute Workshops in 2023: WBE & AI safety, Cryptography & AI safety, XHope, Space, and Atomically Precise Manufacturing', /* title */
        '2023-01-16', /* publication_date */
        NULL, /* modified_date */
        'Elteerkers', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Elteerkers’ post outlines Foresight Institute''s 2023 workshops, highlighting topics such as Whole Brain Emulation (WBE), cryptography, and AI safety, with the Future of Humanity Institute’s Anders Sandberg chairing discussions on WBE technology and its long-term strategic and ethical implications.' /* notes */
    )
      ,(
        'https://forum.effectivealtruism.org/posts/meTqCDCNzYgYmkF76/implications-of-quantum-computing-for-artificial', /* url */
        'Implications of Quantum Computing for Artificial Intelligence alignment research (ABRIDGED)', /* title */
        '2019-09-05', /* publication_date */
        NULL, /* modified_date */
        'Jaime Sevilla', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'General discussion of organizational practices', /* document_scope */
        'AI safety', /* cause_area */
        'Markus Anderljung discusses GovAI''s ongoing projects at the Future of Humanity Institute, highlighting AI governance research priorities, hiring needs, and the broader impact of European AI policy.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/r5ZaEPbxHnM3cc5b8/supporting-global-coordination-in-ai-development-why-and-how', /* url */
        'Supporting global coordination in AI development: Why and how to contribute to international AI standards', /* title */
        '2019-04-19', /* publication_date */
        NULL, /* modified_date */
        'Pcihon', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'General discussion of organizational practices', /* document_scope */
        'AI safety', /* cause_area */
        'Pichon discusses the Future of Humanity Institute''s white paper on international AI standards, emphasizing how globally coordinated standards can mitigate AI risks and promote safety through collaboration among nations and labs.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/n5agKCYxzxiuX8f4X/what-questions-should-we-ask-speakers-at-the-stanford', /* url */
        'What Questions Should We Ask Speakers at the Stanford Existential Risks Conference?', /* title */
        '2021-04-10', /* publication_date */
        NULL, /* modified_date */
        'Kuhanj', /* author */
        'Effective Altruism Forum', /* publisher */
        'Future of Humanity Institute', /* affected_organizations */
        NULL, /* affected_people */
        'General discussion of organizational practices', /* document_scope */
        'AI safety', /* cause_area */
        'The article invites community-suggested questions for speakers at the Stanford Existential Risks Conference, including existential risk experts like Ajeya Cotra and key figures from the Future of Humanity Institute, to guide discussions on mitigating existential threats.' /* notes */
    )
;

      