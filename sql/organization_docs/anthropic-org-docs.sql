insert into organization_documents(url, title, publication_date, modified_date, author, publisher, affected_organizations, affected_people, document_scope, cause_area, notes) values
   (
        'https://www.anthropic.com/news/core-views-on-ai-safety', /* url */
        'Core Views on AI Safety: When, Why, What, and How', /* title */
        '2023-03-08', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The blog post outlines Anthropic''s key perspectives on AI safety, focusing on the potential risks of AI misalignment, timelines for addressing these concerns, and strategic approaches for mitigating long-term harms.' /* notes */
    )
      ,(
        'https://www.anthropic.com/news/uk-ai-safety-summit',  /* url */
        'Dario Amodei’s prepared remarks from the AI Safety Summit on Anthropic’s Responsible Scaling Policy', /* title */
        '2023-11-03', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'An overview of Anthropic''s Responsible Scaling Policy (RSP), outlining their approach to monitoring AI risks, implementing safety measures, and encouraging regulatory frameworks for responsible AI development.' /* notes */
    )
     ,(
        'https://www.anthropic.com/news/anthropics-responsible-scaling-policy',  /* url */
        'Anthropic''s Responsible Scaling Policy', /* title */
        '2023-09-19', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post announcing the release of Anthropic''s Responsible Scaling Policy (RSP), outlining protocols to manage catastrophic risks posed by increasingly advanced AI systems.' /* notes */
    )
    ,(
        'https://www.anthropic.com/news/frontier-threats-red-teaming-for-ai-safety',  /* url */
        'Frontier Threats Red Teaming for AI Safety', /* title */
        '2023-06-26', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post detailing Anthropic''s approach to frontier threats red teaming, focusing on biological risks, findings from their red teaming efforts, and plans to scale up evaluations and mitigations for AI safety' /* notes */
    )
    ,(
        'https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback',  /* url */
        'Constitutional AI: Harmlessness from AI Feedback', /* title */
        '2022-12-15', /* publication_date */
        NULL, /* modified_date */
        'Anthropic', /* author */
        'Anthropic', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A research article discussing methods for training AI systems to self-supervise and improve their behavior through Constitutional AI, combining supervised learning and reinforcement learning without human-labeled harmful outputs.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/pbNDtCx3hAR6th4kc/rishi-sunak-mentions-existential-threats-in-talk-with-openai',  /* url */
        'Rishi Sunak mentions "existential threats" in talk with OpenAI, DeepMind, Anthropic CEOs', /* title */
        '2023-05-25', /* publication_date */
        NULL, /* modified_date */
        'Arjun Panickssery', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI|DeepMind', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Arjun Panickssery summarizes a discussion between the UK Prime Minister and CEOs on the risks of AI, covering issues like disinformation and existential threats, along with safety measures and international collaboration.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/aTQmYafRSqe4xBkeH/jan-leike-i-m-excited-to-join-anthropicai-to-continue-the',  /* url */
        'Jan Leike: "I''m excited to join @AnthropicAI to continue the superalignment mission!"', /* title */
        '2024-05-28', /* publication_date */
        NULL, /* modified_date */
        'Defun', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        'Jan Leike', /* affected_people */
        'Successful hire', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post by Jan Leike announcing his new position at Anthropic AI, where he expresses enthusiasm for continuing his work in AI alignment and safety.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/PFD8MJBEmpZLe54x9/anthropic-announces-new-s-o-t-a-claude-3',  /* url */
        'Anthropic Announces new S.O.T.A. Claude 3"', /* title */
        '2024-03-04', /* publication_date */
        NULL, /* modified_date */
        'Joseph Miller', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post by Joseph Miller announcing the release of Anthropic''s state-of-the-art Claude 3 model, highlighting its new capabilities and advancements in AI safety research.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/DfnaKtqeKPAM8mJwD/podcast-tamera-lanham-on-ai-risk-threat-models-alignment',  /* url */
        'Podcast: Tamera Lanham on AI risk, threat models, alignment proposals, externalized reasoning oversight, and working at Anthropic"', /* title */
        '2022-12-21', /* publication_date */
        NULL, /* modified_date */
        'Akash', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'A summary of an interview with Tamera Lanham, a research resident at Anthropic, discussing her journey into AI alignment, her work on externalized reasoning oversight, and her insights on AI risks and safety.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/jmfayiD4x9DGnFAhD/ai-safety-newsletter-37-us-launches-antitrust-investigations',  /* url */
        'AI Safety Newsletter #37: US Launches Antitrust Investigations Plus, recent criticisms of OpenAI and Anthropic, and a summary of Situational Awareness"', /* title */
        '2024-06-18', /* publication_date */
        NULL, /* modified_date */
        'Center for AI Safety| Corin Katzke| AlexaPanYue| Julius| Dan H', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI|Microsoft|Nvidia', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'A newsletter from the Center for AI Safety covering recent antitrust investigations into Nvidia, OpenAI, and Microsoft, along with developments in AI safety and governance.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/N28dn7J4FF9AaWbTN/197-on-whether-anthropic-s-ai-safety-policy-is-up-to-the',  /* url */
        '#197 – On whether Anthropic''s AI safety policy is up to the task (Nick Joseph on The 80,000 Hours Podcast)"', /* title */
        '2024-08-22', /* publication_date */
        NULL, /* modified_date */
        '80000_Hours', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'An interview with Nick Joseph by 80,000 Hours discussing Anthropic''s responsible scaling policy and the challenges of ensuring AI safety as capabilities increase.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/75KAanpuYFJBfAkhp/anthropic-google-microsoft-and-openai-announce-executive',  /* url */
        'Anthropic, Google, Microsoft & OpenAI announce Executive Director of the Frontier Model Forum & over $10 million for a new AI Safety Fund', /* title */
        '2024-10-25', /* publication_date */
        NULL, /* modified_date */
        'Zach Stein-Perlman', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI|Microsoft|Google', /* affected_organizations */
         NULL, /* affected_people */
        'Successful hire', /* document_scope */
        'AI safety', /* cause_area */
        'A blog post by Zach Stein-Perlman announcing the appointment of Chris Meserole as Executive Director of the Frontier Model Forum, backed by Anthropic, Google, Microsoft, and OpenAI, alongside the launch of a $10 million AI Safety Fund supported by philanthropic partners to advance research in AI safety.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/JgAvau7rhmMGwscBA/would-an-anthropic-openai-merger-be-good-for-ai-safety',  /* url */
        'Would an Anthropic/OpenAI merger be good for AI safety?', /* title */
        '2023-11-22', /* publication_date */
        NULL, /* modified_date */
        'M', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|OpenAI', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'M reports that OpenAI''s board, including two Effective Altruists (EAs), considered a merger with Anthropic, which is more safety-focused, potentially leading to less competition and a slower pace in AI development.' /* notes */
    )
     ,(
        'https://forum.effectivealtruism.org/posts/DDDyTvuZxoKStm92M/ai-safety-needs-great-engineers',  /* url */
        'AI Safety Needs Great Engineers', /* title */
        '2021-11-24', /* publication_date */
        NULL, /* modified_date */
        'Andy Jones', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Andy Jones outlines the urgent need for skilled engineers in AI safety labs like Anthropic, emphasizing the role of engineers in building custom infrastructure for AI experiments and encouraging those capable of contributing to major machine learning libraries to apply.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/snto3JZs6HrgvsoJG/the-tech-industry-is-the-biggest-blocker-to-meaningful-ai',  /* url */
        'The Tech Industry is the Biggest Blocker to Meaningful AI Safety Regulations', /* title */
        '2024-08-16', /* publication_date */
        NULL, /* modified_date */
        'Garrison', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Benjamin Todd discusses the potential crash of AI stocks, its implications for AI safety, and the impact it may have on funding, public sentiment, and long-term AI timelines.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/gkfMLX4NWZdmpikto/critiques-of-prominent-ai-safety-labs-conjecture',  /* url */
        'Critiques of prominent AI safety labs: Conjecture', /* title */
        '2023-06-12', /* publication_date */
        NULL, /* modified_date */
        'Omega', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Omega critiques prominent AI safety labs, with a focus on Anthropic, analyzing their approaches and effectiveness in advancing AI safety.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/Y2xbKLjEmL6dCd2Z6/uk-government-to-host-first-global-summit-on-ai-safety',  /* url */
        'UK government to host first global summit on AI Safety', /* title */
        '2023-06-08', /* publication_date */
        NULL, /* modified_date */
        'David Nash', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|Google DeepMind', /* affected_organizations */
         NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'David Nash highlights Anthropic''s commitment to AI safety, with CEO Dario Amodei emphasizing the importance of global collaboration, as the UK strengthens its position in AI development with key partnerships and initiatives.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/h22mEkh9o5vCQE8Ti/dario-amodei-machines-of-loving-grace', /* url */
        'Dario Amodei — Machines of Loving Grace', /* title */
        '2024-10-12', /* publication_date */
        NULL, /* modified_date */
        'Matrice Jacobine', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        'Dario Amodei', /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'The article by Matrice Jacobine focuses on Anthropic CEO Dario Amodei''s perspective on the potential positive impact of AI, emphasizing that addressing AI risks is crucial to unlocking its transformative benefits.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/fKMPa7cxSnBCymuRm/is-pausing-ai-possible', /* url */
        'Is Pausing AI Possible?', /* title */
        '2024-10-12', /* publication_date */
        NULL, /* modified_date */
        'Richard Annilo', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Richard Annilo, the author explores the challenges and feasibility of pausing AI development, with a significant focus on Anthropic’s efforts and strategies in addressing AI risks.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/uGDCaPFaPkuxAowmH/anthropic-core-views-on-ai-safety-when-why-what-and-how', /* url */
        'Anthropic: Core Views on AI Safety: When, Why, What, and How', /* title */
        '2023-03-09', /* publication_date */
        NULL, /* modified_date */
        'Jonmenaster', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article by Jon Menaster offers a comprehensive overview of Anthropic''s core views on AI safety, addressing the timeline, reasons, focus areas, and approaches to mitigating AI-related risks.' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/WDeKmM87KB6NLKuBm/has-anthropic-already-made-the-externally-legible', /* url */
        'Has Anthropic already made the externally legible commitments that it planned to make?', /* title */
        '2024-03-12', /* publication_date */
        NULL, /* modified_date */
        'Ofer', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article, written by Ofer and answered by Neel Nanda, discusses whether Anthropic has made its promised externally legible commitments regarding the development of AI models beyond a certain capability threshold, with reference to their Responsible Scaling Policy..' /* notes */
    )
    ,(
        'https://forum.effectivealtruism.org/posts/gbPthwLw3NovHAJdp/software-engineering-career-review', /* url */
        'Software engineering - Career review', /* title */
        '2022-02-08', /* publication_date */
        NULL, /* modified_date */
        'Benjamin Hilton| 80000_Hours', /* author */
        'Effective Altruism Forum', /* publisher */
        'Anthropic|Ought| Secure DNA Project|Momentum|Telis Bioscience ', /* affected_organizations */
        NULL, /* affected_people */
        'Job experience', /* document_scope */
        NULL, /* cause_area */
        'The article provides an overview of Anthropic''s recent software engineering hiring practices, focusing on lessons learned during the recruitment process.' /* notes */
    ) 
     ,(
        'https://time.com/6980000/anthropic/', /* url */
        'Inside Anthropic, the AI Company Betting That Safety Can Be a Winning Strategy', /* title */
        '2024-05-30', /* publication_date */
        NULL, /* modified_date */
        'Billy Perrigo', /* author */
        'Time', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article provides an in-depth look at Anthropic, focusing on CEO Dario Amodei''s decision to withhold the release of their advanced AI, Claude, in favor of prioritizing AI safety and fostering industry-wide responsibility, despite the potential for significant financial loss.' /* notes */
    ) 
     ,(
        'https://www.cnbc.com/2024/08/29/openai-and-anthropic-agree-to-let-us-ai-safety-institute-test-models.html', /* url */
        'OpenAI and Anthropic agree to let U.S. AI Safety Institute test and evaluate new models', /* title */
        '2024-08-29', /* publication_date */
        '2024-08-29', /* modified_date */
        'Hayden Field', /* author */
        'CNBC', /* publisher */
        'Anthropic|OpenAI|U.S. AI Safety Institute', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Hayden Field reports that Anthropic has partnered with the U.S. AI Safety Institute to conduct pre-release safety testing on its AI models, reinforcing the company''s focus on identifying and mitigating AI risks to ensure responsible development.' /* notes */
    ) 
    ,(
        'https://www.forbes.com/sites/timabansal/2024/01/16/openai-or-anthropic-which-will-keep-you-more-safe/', /* url */
        'Which Company Will Ensure AI Safety? OpenAI Or Anthropic', /* title */
        '2024-01-16', /* publication_date */
        '2024-01-16', /* modified_date */
        'Tima Bansal', /* author */
        'Forbes', /* publisher */
        'Anthropic|OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article contrasts OpenAI''s recent governance changes with Anthropic''s stronger focus on AI safety, highlighting how Anthropic''s Public-Benefit Corporation (PBC) and Long-Term Benefit Trust structure embed ethical oversight into its operations, positioning it as a leader in safe AI development.' /* notes */
    ) 
    ,(
        'https://www.cio.com/article/2130038/ex-open-ai-researcher-jan-leike-joins-anthropic-amid-ai-safety-concerns.html', /* url */
        'Ex-Open AI researcher Jan Leike joins Anthropic amid AI safety concerns', /* title */
        '2024-05-29', /* publication_date */
        NULL, /* modified_date */
        'Gyana Swain', /* author */
        'CIO', /* publisher */
        'Anthropic|OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Successful hire', /* document_scope */
        'AI safety', /* cause_area */
        'Jan Leike, a former OpenAI researcher, joins Anthropic to focus on scalable oversight and AI safety, following concerns over OpenAI''s safety culture.' /* notes */
    ) 
    ,(
        'https://coingeek.com/california-waters-down-ai-safety-bill-to-appease-industry-opposition/', /* url */
        'California waters down AI safety bill to appease industry opposition', /* title */
        '2024-10-15', /* publication_date */
        NULL, /* modified_date */
        'James Field', /* author */
        'Coingeek', /* publisher */
        'Anthropic|OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'California lawmakers revised the AI safety bill SB-1074 following opposition from the industry, including AI firm Anthropic, which influenced changes related to enforcement penalties and oversight to balance innovation with safety.' /* notes */
    ) 
    ,(
        'https://www.pymnts.com/artificial-intelligence-2/2024/the-week-in-ai-anthropics-ai-safety-initiative-regulation-battles-and-investor-alerts-the-ai-landscape-shifts/', /* url */
        'The Week in AI: Anthropic’s AI Safety Initiative, Regulation Battles, and Investor Alerts: The AI Landscape Shifts', /* title */
        '2024-06-05', /* publication_date */
        NULL, /* modified_date */
        'PYMNTS', /* author */
        'PYMNTS', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Anthropic launches a new AI safety initiative aimed at establishing benchmarks for advanced AI evaluations, focusing on cybersecurity and threat assessments, as global regulations tighten and investor interest grows.' /* notes */
    )
    ,(
        'https://www.datasciencecentral.com/openai-and-anthropic-hopes-for-ai-alignment-and-safety-should-not-be-centralized/', /* url */
        'OpenAI and Anthropic: Hopes for AI alignment and safety should not be centralized', /* title */
        '2024-09-04', /* publication_date */
        NULL, /* modified_date */
        'David Stephen', /* author */
        'Data Science Central', /* publisher */
        'Anthropic|OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'David Stephen critiques the centralized approach to AI safety and alignment efforts by Anthropic and OpenAI, emphasizing the need for broader, more decentralized and interdisciplinary solutions to effectively mitigate AI risks and harms.' /* notes */
    )
    ,(
        'https://time.com/6985504/openai-google-deepmind-employees-letter/', /* url */
        'Employees Say OpenAI and Google DeepMind Are Hiding Dangers From the Public', /* title */
        '2024-06-04', /* publication_date */
        NULL, /* modified_date */
        'Solcyré Burga', /* author */
        'Time', /* publisher */
        'Anthropic|OpenAI|Google DeepMind', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'A group of current and former employees from AI companies, including Anthropic, raised concerns in a public letter about the dangers of advanced AI systems, calling for greater transparency and regulation to address risks such as misinformation, bias, and potential human extinction.' /* notes */
    )
    ,(
        'https://www.ft.com/content/07611b74-3d69-4579-9089-f2fc2af61baa', /* url */
        'AI start-up Anthropic accused of ‘egregious’ data scraping', /* title */
        '2024-07-26', /* publication_date */
        NULL, /* modified_date */
        'George Hammond ', /* author */
        'Financial Times', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article discusses accusations against Anthropic, an AI start-up, for allegedly engaging in aggressive data scraping from websites to train its AI models, despite publishers'' requests to stop, raising concerns about the ethics of such practices.' /* notes */
    )
     ,(
        'https://www.pymnts.com/artificial-intelligence-2/2024/openai-co-founder-john-schulman-joins-anthropic/', /* url */
        'OpenAI Co-Founder John Schulman Joins Anthropic', /* title */
        '2024-08-06', /* publication_date */
        NULL, /* modified_date */
        NULL, /* author */
        'PYMNTS', /* publisher */
        'Anthropic|OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Successful hire', /* document_scope */
        'AI safety', /* cause_area */
        'John Schulman, co-founder of OpenAI, has left the OpenAI to join Anthropic, citing a desire to deepen his focus on AI alignment and work alongside experts in the field.' /* notes */
    )
     ,(
        'https://www.technologyreview.com/2024/07/22/1095193/ai-companies-promised-the-white-house-to-self-regulate-one-year-ago-whats-changed/', /* url */
        'AI companies promised to self-regulate one year ago. What’s changed?', /* title */
        '2022-07-22', /* publication_date */
        NULL, /* modified_date */
        'Melissa Heikkilä', /* author */
        'MIT Technology Review', /* publisher */
        'Anthropic|OpenAI|Google|Inflection|Meta|Microsoft', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'The article highlights that, one year after AI companies made voluntary commitments to self-regulate, there has been some progress, but significant gaps remain. These companies—Amazon, Anthropic, Google, Inflection, Meta, Microsoft, and OpenAI—have made strides in technical measures like red-teaming and watermarking, but issues such as transparency and meaningful accountability are still lacking.' /* notes */
    )
     ,(
        'https://www.datasciencecentral.com/openai-and-anthropic-hopes-for-ai-alignment-and-safety-should-not-be-centralized/', /* url */
        'How Anthropic has doubled down on AI safety', /* title */
        '2024-03-19', /* publication_date */
        NULL, /* modified_date */
        'Mark Sullivan', /* author */
        'Fast Company', /* publisher */
        'Anthropic|OpenAI', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Mark Sullivan provides an overview of how Anthropic doubled down on AI safety in 2023 by raising $7 billion, launching Claude 2 with enhanced capabilities, and pioneering a "Constitutional AI" approach to align its models with ethical principles.' /* notes */
    )
    ,(
        'https://www.anthropic.com/news/model-safety-bug-bounty', /* url */
        'Expanding our model safety bug bounty program', /* title */
        '2024-08-08', /* publication_date */
        NULL, /* modified_date */
        NULL, /* author */
        'Anthropic', /* publisher */
        NULL, /* affected_organizations */
        NULL, /* affected_people */
        'Organization operations', /* document_scope */
        'AI safety', /* cause_area */
        'Anthropic announces the expansion of its model safety bug bounty program, focusing on identifying and mitigating universal jailbreaks in high-risk domains such as CBRN and cybersecurity.' /* notes */
    )
    ,(
        'https://www.fastcompany.com/90948058/how-anthropics-daniela-amodei-is-keeping-ai-grounded-in-safety', /* url */
        'How Anthropic’s Daniela Amodei is keeping AI from spinning out of control', /* title */
        '2024-09-06', /* publication_date */
        NULL, /* modified_date */
        'Mark Sullivan', /* author */
        'Fast Company', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Job experience', /* document_scope */
        'AI safety', /* cause_area */
        'Daniela Amodei, co-founder and president of Anthropic, leads efforts to build AI models that prioritize safety, transparency, and human feedback, ensuring they are helpful, honest, and harmless.' /* notes */
    )
    ,(
        'https://www.fastcompany.com/90879287/ron-conway-responsible-ai', /* url */
        'Why Internet ‘godfather’ Ron Conway called a meeting to discuss responsible AI', /* title */
        '2023-04-10', /* publication_date */
        NULL, /* modified_date */
        'Mark Sullivan', /* author */
        'Fast Company', /* publisher */
        'Anthropic', /* affected_organizations */
        NULL, /* affected_people */
        'Third-party commentary on organization', /* document_scope */
        'AI safety', /* cause_area */
        'Ron Conway convened a meeting with leaders from major AI companies, including Anthropic, to discuss responsible AI development, focusing on best practices and policy frameworks amid rapid advancements in generative AI.' /* notes */
    )
;
